import streamlit as st
import pandas as pd
import numpy as np
import google.generativeai as genai
import pickle
import os

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ç›¸ç¶šãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢",
    page_icon="ğŸ”",
    layout="wide"
)

# Gemini APIè¨­å®šï¼ˆStreamlit Secretsã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
genai.configure(api_key=st.secrets["GEMINI_API_KEY"])

EMBEDDING_MODEL = "gemini-embedding-001"

@st.cache_data
def load_data():
    """ãƒ‡ãƒ¼ã‚¿ã¨embeddingã‚’èª­ã¿è¾¼ã¿ï¼ˆäº‹å‰ä½œæˆæ¸ˆã¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ï¼‰"""
    df = pd.read_excel("RAGãƒ‡ãƒ¼ã‚¿/columns_articles_with_summary.xlsx")

    # ã‚¿ã‚¤ãƒˆãƒ«+æœ¬æ–‡ã®Embeddingï¼ˆRAGç”¨ï¼‰
    with open("embeddings_cache.pkl", "rb") as f:
        embeddings_full = pickle.load(f)
    df["embedding"] = embeddings_full

    # ã‚¿ã‚¤ãƒˆãƒ«+è¦ç´„ã®Embeddingï¼ˆæ¯”è¼ƒç”¨ï¼‰
    with open("embeddings_summary_cache.pkl", "rb") as f:
        embeddings_summary = pickle.load(f)
    df["embedding_summary"] = embeddings_summary

    # ã‚¿ã‚¤ãƒˆãƒ«+ãƒšãƒ«ã‚½ãƒŠè¦ç´„ã®Embeddingï¼ˆæ–°è¦ï¼‰
    with open("embeddings_cache_new_rin.pkl", "rb") as f:
        embeddings_new_rin = pickle.load(f)
    df["embedding_new_rin"] = embeddings_new_rin

    return df

def get_query_embedding(text):
    result = genai.embed_content(
        model=EMBEDDING_MODEL,
        content=text
    )
    return result['embedding']

def cosine_similarity(a, b):
    a = np.array(a)
    b = np.array(b)
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

def search_similar_titles(df, query, top_k=5, embedding_col='embedding'):
    query_embedding = get_query_embedding(query)

    similarities = []
    for idx, row in df.iterrows():
        sim = cosine_similarity(query_embedding, row[embedding_col])
        
        similarities.append({
            'title': row['title'],
            'body': row['body'],
            'summary': row['summary'] if pd.notna(row['summary']) else '',
            'generic_summary': row['æ±ç”¨è¦ç´„'] if pd.notna(row['æ±ç”¨è¦ç´„']) else '',
            'similarity': sim
        })

    similarities.sort(key=lambda x: x['similarity'], reverse=True)
    return similarities[:top_k]

def generate_rag_response(df, user_query, top_k=3, embedding_col='embedding'):
    model = genai.GenerativeModel("gemini-2.5-flash")
    search_results = search_similar_titles(df, user_query, top_k=top_k, embedding_col=embedding_col)
    
    context = "\n\n".join([
        f"ã€è¨˜äº‹{i+1}ã€‘ã‚¿ã‚¤ãƒˆãƒ«: {r['title']}\nå†…å®¹: {r['body']}"
        for i, r in enumerate(search_results)
    ])
    
    prompt = f"""ä»¥ä¸‹ã®å‚è€ƒè¨˜äº‹ã‚’å…ƒã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚

ã€å‚è€ƒè¨˜äº‹ã€‘
{context}

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘
{user_query}

ã€å›ç­”ã€‘"""
    
    response = model.generate_content(prompt)
    return response.text, search_results

# ãƒ¡ã‚¤ãƒ³ç”»é¢
st.title("ğŸ” ç›¸ç¶šãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢")
st.caption("Gemini 2.5 Flash + RAG ãƒ‡ãƒ¢ç‰ˆ")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
with st.sidebar:
    if st.button("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"):
        st.cache_data.clear()
        st.rerun()

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
    df = load_data()

# Embeddingæ¬¡å…ƒæ•°ã‚’è¡¨ç¤º
embed_dim = len(df["embedding"].iloc[0]) if len(df) > 0 else 0
st.success(f"âœ… {len(df)}ä»¶ã®è¨˜äº‹ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆEmbedding: {embed_dim}æ¬¡å…ƒï¼‰")

# æ¤œç´¢UI
st.divider()
query = st.text_input("ğŸ” è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", placeholder="ä¾‹: ç›¸ç¶šç¨ã«ã¤ã„ã¦æ•™ãˆã¦")

col1, col2, col3 = st.columns([1, 2, 2])
with col1:
    top_k = st.selectbox("æ¤œç´¢ä»¶æ•°", [3, 5, 10], index=0)
with col2:
    embedding_type = st.radio(
        "Embeddingç¨®é¡",
        ["ã‚¿ã‚¤ãƒˆãƒ«+æœ¬æ–‡", "ã‚¿ã‚¤ãƒˆãƒ«+è¦ç´„", "ã‚¿ã‚¤ãƒˆãƒ«+ãƒšãƒ«ã‚½ãƒŠè¦ç´„"],
        horizontal=True
    )
with col3:
    search_mode = st.radio("æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰", ["ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ã®ã¿", "AIå›ç­”ç”Ÿæˆ"], horizontal=True)

# é¸æŠã«å¿œã˜ã¦embeddingã‚«ãƒ©ãƒ ã‚’æ±ºå®š
if embedding_type == "ã‚¿ã‚¤ãƒˆãƒ«+æœ¬æ–‡":
    embedding_col = "embedding"
elif embedding_type == "ã‚¿ã‚¤ãƒˆãƒ«+è¦ç´„":
    embedding_col = "embedding_summary"
else:  # ã‚¿ã‚¤ãƒˆãƒ«+ãƒšãƒ«ã‚½ãƒŠè¦ç´„
    embedding_col = "embedding_new_rin"

if st.button("æ¤œç´¢", type="primary") and query:
    with st.spinner("æ¤œç´¢ä¸­..."):
        if search_mode == "ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ã®ã¿":
            results = search_similar_titles(df, query, top_k=top_k, embedding_col=embedding_col)

            st.subheader("æ¤œç´¢çµæœ")
            st.caption(f"ä½¿ç”¨Embedding: {embedding_type}")
            for i, r in enumerate(results, 1):
                with st.expander(f"{i}. {r['title']} (é¡ä¼¼åº¦: {r['similarity']:.3f})"):
                    if embedding_type == "ã‚¿ã‚¤ãƒˆãƒ«+è¦ç´„":
                        st.write(r['summary'])
                    elif embedding_type == "ã‚¿ã‚¤ãƒˆãƒ«+ãƒšãƒ«ã‚½ãƒŠè¦ç´„":
                        st.write(r['generic_summary'])
                    else:
                        st.write(r['body'])
        else:
            answer, sources = generate_rag_response(df, query, top_k=top_k, embedding_col=embedding_col)
            
            st.subheader("AIå›ç­”")
            st.caption(f"ä½¿ç”¨Embedding: {embedding_type}")
            st.write(answer)

            st.subheader("å‚ç…§å…ƒè¨˜äº‹")
            for i, r in enumerate(sources, 1):
                with st.expander(f"{i}. {r['title']} (é¡ä¼¼åº¦: {r['similarity']:.3f})"):
                    if embedding_type == "ã‚¿ã‚¤ãƒˆãƒ«+è¦ç´„":
                        st.write(r['summary'])
                    elif embedding_type == "ã‚¿ã‚¤ãƒˆãƒ«+ãƒšãƒ«ã‚½ãƒŠè¦ç´„":
                        st.write(r['generic_summary'])
                    else:
                        st.write(r['body'])